import { LLMConfig, LLMResponse, ChatMessage } from '../types/index';
import { GoogleGenerativeAI } from '@google/generative-ai';
import chalk from 'chalk';

export class LLMService {
  private config: LLMConfig;
  private geminiClient?: GoogleGenerativeAI;

  constructor(config: LLMConfig) {
    this.config = config;
    this.initializeClient();
  }

  private initializeClient(): void {
    switch (this.config.provider) {
      case 'gemini':
        if (!this.config.apiKey) {
          throw new Error('Google APIå¯†é’¥æœªè®¾ç½®ã€‚è¯·è®¾ç½®GOOGLE_API_KEYç¯å¢ƒå˜é‡ã€‚');
        }
        this.geminiClient = new GoogleGenerativeAI(this.config.apiKey);
        break;
      
      case 'mock':
        // æ¨¡æ‹Ÿæ¨¡å¼ï¼Œä¸éœ€è¦åˆå§‹åŒ–å®¢æˆ·ç«¯
        break;
      
      default:
        throw new Error(`ä¸æ”¯æŒçš„LLMæä¾›å•†: ${this.config.provider}`);
    }
  }

  public async generateResponse(messages: ChatMessage[], systemPrompt?: string): Promise<LLMResponse> {
    try {
      switch (this.config.provider) {
        case 'gemini':
          return await this.generateGeminiResponse(messages, systemPrompt);
        
        case 'mock':
          return await this.generateMockResponse(messages);
        
        default:
          throw new Error(`ä¸æ”¯æŒçš„LLMæä¾›å•†: ${this.config.provider}`);
      }
    } catch (error) {
      console.error(chalk.red('LLMè°ƒç”¨å¤±è´¥:'), error);
      throw error;
    }
  }

  private async generateGeminiResponse(messages: ChatMessage[], systemPrompt?: string): Promise<LLMResponse> {
    if (!this.geminiClient) {
      throw new Error('Geminiå®¢æˆ·ç«¯æœªåˆå§‹åŒ–');
    }

    const model = this.geminiClient.getGenerativeModel({ 
      model: this.config.model,
      generationConfig: {
        maxOutputTokens: this.config.maxTokens,
        temperature: this.config.temperature,
      }
    });

    // è·å–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
    const lastUserMessage = messages.filter(m => m.role === 'user').pop();
    if (!lastUserMessage) {
      throw new Error('æ²¡æœ‰æ‰¾åˆ°ç”¨æˆ·æ¶ˆæ¯');
    }

    // æ„å»ºpromptï¼ŒåŠ ä¸Šç³»ç»Ÿæç¤ºå’ŒåŸºæœ¬çš„å¯¹è¯ä¸Šä¸‹æ–‡
    let prompt = '';
    
    if (systemPrompt) {
      prompt += `${systemPrompt}\n\n`;
    }
    
    // å¦‚æœæœ‰å†å²æ¶ˆæ¯ï¼ŒåªåŒ…å«æœ€è¿‘çš„å‡ æ¡
    const recentMessages = messages.slice(-4); // åªä¿ç•™æœ€è¿‘4æ¡æ¶ˆæ¯
    if (recentMessages.length > 1) {
      recentMessages.slice(0, -1).forEach(msg => {
        const role = msg.role === 'user' ? 'ç”¨æˆ·' : 'åŠ©æ‰‹';
        prompt += `${role}: ${msg.content}\n`;
      });
      prompt += '\n';
    }
    
    // æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
    prompt += `ç”¨æˆ·: ${lastUserMessage.content}\n`;
    prompt += 'åŠ©æ‰‹: ';

    console.log(chalk.green('ğŸ¤– prompt------:'), prompt);

    const result = await model.generateContent(prompt);
    const response = await result.response;
    const content = response.text() || 'æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç”Ÿæˆå›å¤ã€‚';

    // Gemini APIç›®å‰ä¸æä¾›è¯¦ç»†çš„tokenä½¿ç”¨ä¿¡æ¯ï¼Œæˆ‘ä»¬è¿›è¡Œä¼°ç®—
    const estimatedPromptTokens = Math.floor(prompt.length / 4);
    const estimatedCompletionTokens = Math.floor(content.length / 4);

    return {
      content,
      usage: {
        promptTokens: estimatedPromptTokens,
        completionTokens: estimatedCompletionTokens,
        totalTokens: estimatedPromptTokens + estimatedCompletionTokens
      }
    };
  }

  private async generateMockResponse(messages: ChatMessage[]): Promise<LLMResponse> {
    // æ¨¡æ‹Ÿæ€è€ƒæ—¶é—´
    await new Promise(resolve => setTimeout(resolve, 800 + Math.random() * 1200));

    const lastMessage = messages[messages.length - 1];
    const input = lastMessage?.content || '';
    const lowerInput = input.toLowerCase().trim();

    // æ£€æŸ¥æ˜¯å¦åŒ…å«RAGä¸Šä¸‹æ–‡
    if (input.includes('åŸºäºä»¥ä¸‹çŸ¥è¯†åº“ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ï¼š')) {
      // ä½¿ç”¨æ›´ç²¾ç¡®çš„è§£ææ–¹å¼
      const ragPattern = /åŸºäºä»¥ä¸‹çŸ¥è¯†åº“ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ï¼š\s*([\s\S]*?)\s*ç”¨æˆ·é—®é¢˜ï¼š([^]*?)(?:\s*è¯·åŸºäºä¸Šè¿°çŸ¥è¯†åº“ä¿¡æ¯è¿›è¡Œå›ç­”|$)/;
      const match = input.match(ragPattern);
      
      if (match && match[1] && match[2]) {
        const contextPart = match[1].trim();
        const userQuestion = match[2].trim();
        
        // ä»ä¸Šä¸‹æ–‡ä¸­æå–çŸ¥è¯†å†…å®¹
        const knowledgeMatch = contextPart.match(/ã€æ¥æºï¼š[^ã€‘]*ã€‘\s*([\s\S]*?)(?:\s*$)/);
        if (knowledgeMatch && knowledgeMatch[1]) {
          const knowledgeContent = knowledgeMatch[1].trim();
          
          // æ ¹æ®çŸ¥è¯†åº“å†…å®¹å›ç­”é—®é¢˜
          return this.generateResponseFromKnowledge(userQuestion, knowledgeContent);
        }
      }
    }

    // åŸºç¡€å¯¹è¯é€»è¾‘ï¼ˆä¿æŒåŸæœ‰çš„æ¨¡æ‹Ÿé€»è¾‘ï¼‰
    let content = '';

    if (lowerInput.includes('ä½ å¥½') || lowerInput.includes('hello') || lowerInput.includes('hi')) {
      content = 'ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªæ™ºèƒ½AIåŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸æ‚¨å¯¹è¯ã€‚æˆ‘å¯ä»¥å¸®åŠ©æ‚¨è§£ç­”é—®é¢˜ã€è¿›è¡Œè®¨è®ºæˆ–æä¾›ä¿¡æ¯ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ';
    } else if (lowerInput.includes('ä½ æ˜¯è°') || lowerInput.includes('ä»‹ç»') || lowerInput.includes('about')) {
      content = 'æˆ‘æ˜¯ä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„AIåŠ©æ‰‹ï¼Œå…·å¤‡è‡ªç„¶è¯­è¨€ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ã€‚æˆ‘å¯ä»¥å¸®åŠ©æ‚¨å›ç­”é—®é¢˜ã€è¿›è¡Œå¯¹è¯ã€æä¾›å»ºè®®ç­‰ã€‚æˆ‘ä¼šå°½åŠ›ä¸ºæ‚¨æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„ä¿¡æ¯ã€‚';
    } else if (lowerInput.includes('æ—¶é—´') || lowerInput.includes('ç°åœ¨å‡ ç‚¹')) {
      const now = new Date();
      content = `å½“å‰æ—¶é—´æ˜¯ï¼š${now.toLocaleString('zh-CN', { 
        year: 'numeric', 
        month: '2-digit', 
        day: '2-digit', 
        hour: '2-digit', 
        minute: '2-digit', 
        second: '2-digit' 
      })}`;
    } else {
      // ç”Ÿæˆæ›´æ™ºèƒ½çš„é»˜è®¤å›å¤
      const responses = [
        'è¿™æ˜¯ä¸€ä¸ªå¾ˆæœ‰è¶£çš„è¯é¢˜ã€‚èƒ½è¯¦ç»†è¯´è¯´æ‚¨çš„æƒ³æ³•å—ï¼Ÿ',
        'æˆ‘ç†è§£æ‚¨çš„è§‚ç‚¹ã€‚è¿™ä¸ªé—®é¢˜ç¡®å®å€¼å¾—æ·±å…¥æ€è€ƒã€‚',
        'æ„Ÿè°¢æ‚¨åˆ†äº«è¿™ä¸ªä¿¡æ¯ã€‚æ‚¨å¸Œæœ›æˆ‘ä»å“ªä¸ªè§’åº¦æ¥åˆ†æå‘¢ï¼Ÿ',
        'è¿™è®©æˆ‘æƒ³åˆ°äº†ç›¸å…³çš„ä¸€äº›æ¦‚å¿µã€‚æ‚¨æƒ³äº†è§£æ›´å¤šèƒŒæ™¯ä¿¡æ¯å—ï¼Ÿ',
        'å¾ˆå¥½çš„é—®é¢˜ï¼è®©æˆ‘ä¸ºæ‚¨è¯¦ç»†è§£é‡Šä¸€ä¸‹ã€‚',
        'æˆ‘ä¼šå°½åŠ›å¸®åŠ©æ‚¨è§£å†³è¿™ä¸ªé—®é¢˜ã€‚è¯·å‘Šè¯‰æˆ‘æ›´å¤šç»†èŠ‚ã€‚'
      ];
      content = responses[Math.floor(Math.random() * responses.length)] || 'æˆ‘ä¼šå°½åŠ›å¸®åŠ©æ‚¨è§£å†³è¿™ä¸ªé—®é¢˜ã€‚';
    }

    return {
      content,
      usage: {
        promptTokens: Math.floor(lowerInput.length / 4), // å¤§æ¦‚ä¼°ç®—
        completionTokens: Math.floor(content.length / 4),
        totalTokens: Math.floor((lowerInput.length + content.length) / 4)
      }
    };
  }

  private generateResponseFromKnowledge(question: string, knowledge: string): LLMResponse {
    const lowerQuestion = question.toLowerCase().trim();
    const lowerKnowledge = knowledge.toLowerCase();
    
    let content = '';
    
    // æ ¹æ®é—®é¢˜å’ŒçŸ¥è¯†å†…å®¹ç”Ÿæˆå›ç­”
    if (lowerQuestion.includes('å°æ˜') && lowerQuestion.includes('å¥³æœ‹å‹')) {
      if (lowerKnowledge.includes('å¥³æœ‹å‹') && lowerKnowledge.includes('å¯ŒäºŒä»£')) {
        content = 'æ ¹æ®çŸ¥è¯†åº“ä¿¡æ¯ï¼Œæ˜¯çš„ï¼Œå°æ˜æœ‰å¥³æœ‹å‹ã€‚ä»–çš„å¥³æœ‹å‹æ˜¯ä¸€ä¸ªå¯ŒäºŒä»£ï¼Œå¾ˆæ¼‚äº®ä¸”å®¶å¢ƒå¯Œè£•ã€‚';
      } else {
        content = 'æ ¹æ®ç°æœ‰ä¿¡æ¯æ— æ³•ç¡®å®šå°æ˜æ˜¯å¦æœ‰å¥³æœ‹å‹ã€‚';
      }
    } else if (lowerQuestion.includes('å°æ˜') && (lowerQuestion.includes('å¤šå¤§') || lowerQuestion.includes('å¹´é¾„') || lowerQuestion.includes('å²'))) {
      if (lowerKnowledge.includes('20å²')) {
        content = 'æ ¹æ®çŸ¥è¯†åº“ä¿¡æ¯ï¼Œå°æ˜ä»Šå¹´20å²ã€‚';
      } else {
        content = 'æ ¹æ®ç°æœ‰ä¿¡æ¯æ— æ³•ç¡®å®šå°æ˜çš„å¹´é¾„ã€‚';
      }
    } else if (lowerQuestion.includes('å°æ˜') && (lowerQuestion.includes('ä¸“ä¸š') || lowerQuestion.includes('å­¦') || lowerQuestion.includes('å·¥ç¨‹'))) {
      if (lowerKnowledge.includes('åœŸæœ¨å·¥ç¨‹')) {
        content = 'æ ¹æ®çŸ¥è¯†åº“ä¿¡æ¯ï¼Œå°æ˜å­¦çš„æ˜¯åœŸæœ¨å·¥ç¨‹ä¸“ä¸šï¼Œç›®å‰è¿˜æ²¡æœ‰æ¯•ä¸šã€‚';
      } else {
        content = 'æ ¹æ®ç°æœ‰ä¿¡æ¯æ— æ³•ç¡®å®šå°æ˜çš„ä¸“ä¸šã€‚';
      }
    } else {
      // é€šç”¨å›ç­”
      content = `æ ¹æ®çŸ¥è¯†åº“ä¿¡æ¯ï¼š${knowledge.slice(0, 200)}${knowledge.length > 200 ? '...' : ''}`;
    }
    
    return {
      content,
      usage: {
        promptTokens: Math.floor((question.length + knowledge.length) / 4),
        completionTokens: Math.floor(content.length / 4),
        totalTokens: Math.floor((question.length + knowledge.length + content.length) / 4)
      }
    };
  }

  public getConfig(): LLMConfig {
    return { ...this.config };
  }

  public updateConfig(newConfig: Partial<LLMConfig>): void {
    this.config = { ...this.config, ...newConfig };
    this.initializeClient();
  }
} 